"""Script de pr√©diction de la cat√©gorie de produit pour une plainte client.

Ce script :
1. Charge les mod√®les pr√©-entra√Æn√©s (RNN et Word2Vec)
2. Prend une plainte en entr√©e via la ligne de commande
3. Transforme le texte en vecteurs num√©riques
4. Pr√©dit la cat√©gorie de produit financier concern√©

Usage:
    python predict.py "Votre plainte ici"
"""

import os
import sys  # Pour r√©cup√©rer les arguments de ligne de commande

# Configuration pour r√©duire les messages de TensorFlow
# IMPORTANT : Ces lignes DOIVENT √™tre avant l'import de TensorFlow
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"  # 3 = Afficher seulement les erreurs
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"  # D√©sactive les optimisations oneDNN

# Imports des biblioth√®ques n√©cessaires
import numpy as np  # Pour les calculs num√©riques et tableaux
import tensorflow as tf  # Pour charger et utiliser le mod√®le de deep learning
from gensim.models import KeyedVectors  # Pour charger le mod√®le Word2Vec sauvegard√©
from spacy.lang.fr import French  # Pour analyser et d√©couper le texte en fran√ßais
from dotenv import load_dotenv  # Pour charger les variables d'environnement
import json  # Pour charger le mapping des classes

# Configuration suppl√©mentaire pour r√©duire les messages de TensorFlow
tf.get_logger().setLevel('ERROR')  # Ne montre que les erreurs, pas les warnings

def load_models():
    """Charge les mod√®les pr√©-entra√Æn√©s n√©cessaires pour la pr√©diction.
    
    Cette fonction charge :
    - Le mod√®le RNN : le r√©seau de neurones qui fait la pr√©diction
    - Le mod√®le Word2Vec : pour convertir les mots en vecteurs num√©riques
    - Le tokenizer Spacy : pour d√©couper le texte en mots
    
    Returns:
        Tuple contenant (mod√®le_rnn, mod√®le_word2vec, tokenizer_spacy)
    """
    # Charge le mod√®le de deep learning sauvegard√© apr√®s l'entra√Ænement
    # Utiliser la variable d'environnement pour le nom du fichier
    output_file = os.getenv('OUTPUT_FILE', 'complaint_classifier')
    model_path = f"models/{output_file}.keras"
    rnn = tf.keras.models.load_model(model_path)
    print(f"‚úÖ Mod√®le RNN charg√© depuis {model_path}")
    
    # Charge le vocabulaire Word2Vec (les vecteurs de tous les mots appris)
    w2v = KeyedVectors.load("models/w2v.wv")
    print("‚úÖ Mod√®le Word2Vec charg√© depuis models/w2v.wv")
    
    # Charge le mapping des classes
    with open('models/class_mapping.json', 'r', encoding='utf-8') as f:
        class_data = json.load(f)
    print("‚úÖ Mapping des classes charg√© depuis models/class_mapping.json")
    
    # Initialise l'analyseur de texte anglais (les plaintes sont en anglais)
    from spacy.lang.en import English
    nlp = English()
    
    return rnn, w2v, nlp, class_data

def process_comment(comment, w2v, nlp, W2V_SIZE, MAX_LENGTH):
    """Transforme un commentaire texte en matrice de vecteurs Word2Vec.
    
    Cette fonction fait exactement la m√™me transformation que pendant
    l'entra√Ænement pour que le mod√®le comprenne le nouveau commentaire.
    
    Args:
        comment: Le texte du commentaire √† analyser
        w2v: Mod√®le Word2Vec pour convertir les mots en vecteurs
        nlp: Tokenizer Spacy pour d√©couper le texte
        W2V_SIZE: Taille des vecteurs Word2Vec (100)
        MAX_LENGTH: Nombre maximum de mots √† consid√©rer (64)
    
    Returns:
        Matrice numpy de forme (100, 64) repr√©sentant le commentaire
    """
    # Met le texte en minuscules pour uniformiser
    comment = comment.lower()
    
    # D√©coupe le texte en mots et enl√®ve la ponctuation
    tokens = [x.text for x in nlp(comment) if not x.is_punct]
    
    # Cr√©e une matrice vide (100 lignes x 64 colonnes) remplie de z√©ros
    row = np.zeros((W2V_SIZE, MAX_LENGTH))
    
    # Remplit la matrice avec les vecteurs de chaque mot
    for j in range(min(MAX_LENGTH, len(tokens))):
        try:
            # Place le vecteur du mot j dans la colonne j
            row[:, j] = w2v[tokens[j]]
        except KeyError:
            # Si le mot n'a pas √©t√© vu pendant l'entra√Ænement, on laisse des z√©ros
            print(f"Le mot '{tokens[j]}' ne fait pas partie du vocabulaire.")
    
    return row

def predict(comment, rnn, w2v, nlp, W2V_SIZE, MAX_LENGTH, class_data):
    """Pr√©dit la cat√©gorie de produit d'une plainte et retourne les r√©sultats.
    
    Processus de pr√©diction :
    1. Transforme le texte en matrice de vecteurs
    2. Fait passer cette matrice dans le r√©seau de neurones
    3. R√©cup√®re les probabilit√©s pour chaque cat√©gorie de produit
    4. Choisit la cat√©gorie avec la plus haute probabilit√©
    
    Args:
        comment: Texte de la plainte √† analyser
        rnn: Mod√®le de r√©seau de neurones entra√Æn√©
        w2v: Mod√®le Word2Vec
        nlp: Tokenizer Spacy
        W2V_SIZE: Dimension des vecteurs (100)
        MAX_LENGTH: Longueur max (64)
        class_data: Mapping des classes de produits
    
    Returns:
        Tuple contenant:
        - La cat√©gorie de produit pr√©dite
        - Le niveau de confiance en pourcentage
        - Les probabilit√©s d√©taill√©es pour chaque cat√©gorie
    """
    # Transforme le commentaire en matrice num√©rique
    processed_comment = process_comment(comment, w2v, nlp, W2V_SIZE, MAX_LENGTH)
    
    # Fait la pr√©diction avec le mod√®le
    # np.asarray([...]) ajoute une dimension car le mod√®le attend un batch
    # verbose=0 pour ne pas afficher de messages pendant la pr√©diction
    prediction = rnn.predict(np.asarray([processed_comment]), verbose=0)
    
    # Interpr√©tation des r√©sultats
    # Le mod√®le retourne 21 probabilit√©s (une pour chaque cat√©gorie de produit)
    
    # argmax trouve l'indice de la plus haute probabilit√©
    predicted_class = np.argmax(prediction[0])
    
    # R√©cup√®re le nom de la cat√©gorie depuis le mapping
    category_name = class_data['index_to_class'][str(predicted_class)]
    
    # Convertit la probabilit√© en pourcentage
    confidence = prediction[0][predicted_class] * 100
    
    return category_name, confidence, prediction[0]


def main():
    """Fonction principale qui orchestre la pr√©diction.
    
    √âtapes :
    1. Charge les mod√®les sauvegard√©s
    2. R√©cup√®re le commentaire depuis la ligne de commande
    3. Fait la pr√©diction
    4. Affiche les r√©sultats de fa√ßon claire
    """
    # √âTAPE 1 : Chargement des mod√®les
    # Charge le RNN, Word2Vec, le tokenizer et le mapping des classes
    rnn, w2v, nlp, class_data = load_models()
    
    # √âTAPE 2 : R√©cup√©ration du commentaire
    # V√©rifie qu'un commentaire a √©t√© fourni en argument
    if len(sys.argv) < 2:
        print("Usage: python predict.py \"votre commentaire ici\"")
        print("Exemple: python predict.py \"Ce film √©tait vraiment excellent !\"")
        sys.exit(1)  # Quitte le programme avec un code d'erreur
    
    # Joint tous les arguments pour former le commentaire complet
    # (au cas o√π il y aurait des espaces dans le commentaire)
    comment = " ".join(sys.argv[1:])
    
    # √âTAPE 3 : Pr√©diction
    # Analyse le commentaire et pr√©dit la cat√©gorie de produit
    category, confidence, probabilities = predict(comment, rnn, w2v, nlp, W2V_SIZE, MAX_LENGTH, class_data)
    
    # √âTAPE 4 : Affichage des r√©sultats
    print(f"\nüìä Analyse de la plainte:")
    print(f"Texte: \"{comment[:150]}{'...' if len(comment) > 150 else ''}\"")
    
    # Affiche la cat√©gorie principale et la confiance
    print(f"\nüìÅ Cat√©gorie d√©tect√©e: {category}")
    print(f"üí™ Confiance: {confidence:.1f}%")
    
    # Affiche les 5 cat√©gories les plus probables
    print(f"\nüìà Top 5 cat√©gories probables:")
    top_indices = np.argsort(probabilities)[-5:][::-1]
    for idx in top_indices:
        cat_name = class_data['index_to_class'][str(idx)]
        prob = probabilities[idx] * 100
        if prob > 1:  # N'affiche que les probabilit√©s > 1%
            print(f"  ‚Ä¢ {cat_name[:50]}: {prob:.1f}%")

# Point d'entr√©e du script
# Ce code ne s'ex√©cute que si on lance directement ce fichier
# (pas si on l'importe dans un autre fichier)
if __name__ == "__main__":
    # Charge les variables d'environnement depuis le fichier .env
    # Cela permet de configurer les param√®tres sans modifier le code
    load_dotenv(override=True)
    
    # R√©cup√®re les param√®tres de configuration
    # Ces valeurs doivent √™tre identiques √† celles utilis√©es pour l'entra√Ænement
    W2V_SIZE = int(os.getenv("W2V_SIZE", 100))  # Taille des vecteurs Word2Vec
    W2V_MIN_COUNT = int(os.getenv("W2V_MIN_COUNT", 3))  # Fr√©quence min (pas utilis√© ici)
    MAX_LENGTH = int(os.getenv("MAX_LENGTH", 64))  # Nombre max de mots par commentaire
    
    # Lance la fonction principale
    main()