# Classification de Demandes au Service Client

SystÃ¨me de classification automatique des demandes au service client d'une compagnie d'assurance utilisant le Deep Learning (CNN + LSTM) et Word2Vec.

## ğŸ“‹ Description

Ce projet utilise l'intelligence artificielle pour classifier automatiquement les plaintes des clients dans diffÃ©rentes catÃ©gories de produits d'assurance. Le systÃ¨me analyse le texte des plaintes et prÃ©dit la catÃ©gorie appropriÃ©e, permettant ainsi un traitement plus rapide et plus efficace des demandes.

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Au moins 4 GB de RAM pour l'entraÃ®nement

### Ã‰tapes d'installation

1. **Cloner le projet**
```bash
git clone <url-du-projet>
cd support-classification
```

2. **CrÃ©er un environnement virtuel**

Option A - MÃ©thode standard :
```bash
python -m venv venv
source venv/bin/activate  # Sur Linux/Mac
# ou
venv\Scripts\activate  # Sur Windows
```

Option B - Si erreur avec ensurepip :
```bash
# Sur Ubuntu/Debian
sudo apt-get install python3-venv python3-pip
python3 -m venv venv --without-pip
source venv/bin/activate
curl https://bootstrap.pypa.io/get-pip.py | python

# Ou avec virtualenv
pip install virtualenv
virtualenv venv
source venv/bin/activate
```

Option C - Utiliser directement pip sans environnement virtuel (non recommandÃ©) :
```bash
pip install --user -r requirements.txt
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **TÃ©lÃ©charger le modÃ¨le de langue anglaise pour Spacy**
```bash
python -m spacy download en_core_web_md
```

5. **CrÃ©er les dossiers nÃ©cessaires**
```bash
mkdir -p data/raw data/prepared models logs
```

6. **Configuration** (optionnel)

Modifier le fichier `.env` pour ajuster les paramÃ¨tres :
```env
NB_COMMENT = 50000      # Nombre de commentaires pour l'entraÃ®nement
W2V_SIZE = 100         # Dimension des vecteurs Word2Vec
W2V_MIN_COUNT = 3      # FrÃ©quence minimale des mots
MAX_LENGTH = 64        # Longueur maximale des commentaires
```

## ğŸ“Š Analyse des DonnÃ©es

Avant l'entraÃ®nement, il est recommandÃ© d'analyser la distribution des classes dans votre dataset :

```bash
python analyze_classes.py
```

Ce script :
- Lit le fichier `data/raw/complaints.csv`
- Analyse la distribution des catÃ©gories de produits
- Calcule les statistiques (nombre d'observations, pourcentages, dÃ©sÃ©quilibre)
- Sauvegarde les rÃ©sultats dans `data/prepared/analyse_result.json`

### Structure du fichier CSV attendu

Le fichier `complaints.csv` doit contenir au minimum une colonne :
- `Product` : La catÃ©gorie du produit concernÃ© par la plainte

## ğŸ¤– EntraÃ®nement du ModÃ¨le

### PrÃ©paration des donnÃ©es

Placer votre fichier de donnÃ©es `complaints.csv` dans le dossier `data/raw/`. 

âš ï¸ **Note importante** : Le script `train_model.py` actuel est configurÃ© pour un dataset de sentiments de films (`text_sentiment.csv`). Pour l'adapter aux plaintes d'assurance, vous devrez :

1. Modifier le nom du fichier dans `train_model.py` :
```python
# Ligne 197 - Remplacer :
data = pd.read_csv("data/text_sentiment.csv").dropna()
# Par :
data = pd.read_csv("data/raw/complaints.csv").dropna()
```

2. Ajuster les colonnes selon votre structure de donnÃ©es :
   - Colonne de texte : remplacer `"comment"` par le nom de votre colonne de plaintes
   - Colonnes de classes : adapter la fonction `merge_feelings()` pour vos catÃ©gories

### Lancer l'entraÃ®nement

```bash
python train_model.py
```

Le script va :
1. Charger les donnÃ©es depuis le CSV
2. Tokeniser les textes (dÃ©coupage en mots)
3. CrÃ©er des embeddings Word2Vec
4. Transformer les textes en vecteurs numÃ©riques
5. EntraÃ®ner un modÃ¨le hybride CNN + LSTM
6. Sauvegarder les modÃ¨les dans le dossier `models/`

### Suivi de l'entraÃ®nement

Pour visualiser les mÃ©triques d'entraÃ®nement en temps rÃ©el :

```bash
tensorboard --logdir=logs
```

Puis ouvrir http://localhost:6006 dans votre navigateur.

## ğŸ”® PrÃ©diction

Une fois le modÃ¨le entraÃ®nÃ©, vous pouvez faire des prÃ©dictions sur de nouveaux textes :

```bash
python predict.py "Texte de la plainte client Ã  analyser"
```

Exemple :
```bash
python predict.py "Je n'arrive pas Ã  faire une rÃ©clamation pour mon assurance auto suite Ã  un accident"
```

Le script affichera :
- La catÃ©gorie prÃ©dite
- Le niveau de confiance (en %)
- Les probabilitÃ©s dÃ©taillÃ©es pour chaque catÃ©gorie

## ğŸ“ Structure du Projet

```
support-classification/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # DonnÃ©es brutes
â”‚   â”‚   â””â”€â”€ complaints.csv    # Dataset des plaintes
â”‚   â””â”€â”€ prepared/             # DonnÃ©es prÃ©parÃ©es
â”‚       â””â”€â”€ analyse_result.json  # RÃ©sultats de l'analyse
â”‚
â”œâ”€â”€ models/                   # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ w2v.wv               # ModÃ¨le Word2Vec
â”‚   â””â”€â”€ comment_sentiment_rnn.keras  # ModÃ¨le de classification
â”‚
â”œâ”€â”€ logs/                     # Logs TensorBoard
â”‚
â”œâ”€â”€ analyze_classes.py        # Script d'analyse des classes
â”œâ”€â”€ train_model.py           # Script d'entraÃ®nement
â”œâ”€â”€ predict.py               # Script de prÃ©diction
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ .env                     # Configuration
â””â”€â”€ README.md               # Ce fichier
```

## ğŸ”§ Personnalisation

### Adapter le modÃ¨le Ã  vos donnÃ©es

Pour utiliser ce systÃ¨me avec vos propres donnÃ©es de plaintes :

1. **Format des donnÃ©es** : Assurez-vous que votre CSV contient :
   - Une colonne de texte avec les plaintes
   - Une colonne de catÃ©gories/labels

2. **Modifier `train_model.py`** :
   - Ligne 197 : Chemin du fichier CSV
   - Ligne 204 : Nom de la colonne de texte
   - Fonction `merge_feelings()` : Adapter selon vos labels

3. **Ajuster les hyperparamÃ¨tres** dans `.env` selon vos besoins

### Architecture du modÃ¨le

Le modÃ¨le utilise une architecture hybride :
- **Word2Vec** : Pour crÃ©er des embeddings sÃ©mantiques des mots
- **CNN (Convolution 1D)** : Pour dÃ©tecter des patterns locaux dans le texte
- **LSTM** : Pour comprendre les sÃ©quences et le contexte
- **Dense layers** : Pour la classification finale

## âš ï¸ Notes Importantes

1. **MÃ©moire** : L'entraÃ®nement avec 50 000 commentaires nÃ©cessite environ 4 GB de RAM
2. **GPU** : Le code supporte CUDA pour accÃ©lÃ©rer l'entraÃ®nement sur GPU NVIDIA
3. **Temps d'entraÃ®nement** : Environ 30-60 minutes sur CPU, 5-10 minutes sur GPU
4. **DÃ©sÃ©quilibre des classes** : Si certaines catÃ©gories sont sous-reprÃ©sentÃ©es, considÃ©rez :
   - L'utilisation de `class_weight` dans le fit
   - Des techniques de sur-Ã©chantillonnage (SMOTE)
   - Des mÃ©triques adaptÃ©es (Weighted F1-Score)

## ğŸ“ˆ Performances

Les performances du modÃ¨le dÃ©pendent de :
- La qualitÃ© et quantitÃ© des donnÃ©es
- L'Ã©quilibre entre les classes
- Les hyperparamÃ¨tres choisis

Utilisez TensorBoard pour monitorer :
- Loss (entraÃ®nement et validation)
- Accuracy
- Overfitting (Ã©cart train/validation)

## ğŸ¤ Contribution

Pour contribuer au projet :
1. Fork le repository
2. CrÃ©er une branche pour votre feature
3. Commit vos changements
4. Push vers votre branche
5. Ouvrir une Pull Request

## ğŸ“ License

[InsÃ©rer votre license ici]

## ğŸ“§ Contact

[Vos informations de contact]