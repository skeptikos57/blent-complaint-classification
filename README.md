# Classification de Plaintes Service Client - Projet √âducatif

Syst√®me de classification automatique des plaintes clients utilisant le Deep Learning (CNN + LSTM) et Word2Vec. Ce projet √©ducatif d√©montre comment utiliser l'apprentissage profond pour cat√©goriser automatiquement des textes dans 21 cat√©gories de produits financiers diff√©rents.

## üìã Description

Ce projet utilise l'intelligence artificielle pour classifier automatiquement les plaintes des clients dans diff√©rentes cat√©gories de produits financiers (cartes de cr√©dit, pr√™ts immobiliers, comptes bancaires, etc.). Le syst√®me analyse le texte des plaintes en anglais et pr√©dit la cat√©gorie appropri√©e avec un niveau de confiance, permettant ainsi un traitement plus rapide et efficace des demandes clients.

### Pr√©requis de Connaissances

Ce projet est id√©al pour les √©tudiants et d√©veloppeurs ayant :
- Des bases en **Python** (numpy, pandas)
- Une compr√©hension basique du **Machine Learning**
- Un int√©r√™t pour le **Deep Learning** et le **NLP**
- Envie d'apprendre les **r√©seaux de neurones** (CNN, LSTM)

## üéØ Cat√©gories Support√©es

Le syst√®me peut classifier les plaintes dans 21 cat√©gories de produits financiers, incluant :
- Credit reporting and repair services
- Debt collection
- Mortgage
- Credit cards
- Checking/savings accounts
- Student loans
- Vehicle loans
- Payday loans
- Money transfers
- Et plus encore...

## üöÄ Installation Rapide

### Pr√©requis

- Python 3.8 ou sup√©rieur
- pip (gestionnaire de paquets Python)
- Au moins 8 GB de RAM pour l'entra√Ænement complet (4 GB pour le mode r√©duit)
- GPU NVIDIA avec CUDA (optionnel, mais recommand√©)

### Installation

1. **Cloner le projet**
```bash
git clone <url-du-projet>
cd support-classification
```

2. **Cr√©er et activer l'environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Sur Linux/Mac
# ou
venv\Scripts\activate  # Sur Windows
```

3. **Installer les d√©pendances**
```bash
pip install -r requirements.txt
```

4. **T√©l√©charger le mod√®le de langue anglaise pour Spacy**
```bash
python -m spacy download en_core_web_sm
```

5. **Cr√©er les dossiers n√©cessaires**
```bash
mkdir -p data/raw data/prepared models logs
```

## ‚öôÔ∏è Configuration

Le fichier `.env` contient tous les param√®tres configurables :

```env
# Chemin vers le fichier de donn√©es
INPUT_FILE=data/raw/complaints.csv

# Param√®tres d'entra√Ænement
NB_COMMENT=10000        # Nombre d'exemples √† utiliser (10k pour test, 50k+ pour production)
W2V_SIZE=100           # Dimension des vecteurs Word2Vec
W2V_MIN_COUNT=3        # Fr√©quence minimale des mots
MAX_LENGTH=64          # Longueur maximale des textes (64 pour √©conomiser la RAM, 256 pour meilleure pr√©cision)

# Nom du mod√®le
OUTPUT_FILE=complaint_classifier
```

**Conseils de configuration :**
- **D√©veloppement/Test** : `NB_COMMENT=10000`, `MAX_LENGTH=64` (utilise ~2GB RAM)
- **Production** : `NB_COMMENT=50000`, `MAX_LENGTH=256` (utilise ~8GB RAM, meilleure pr√©cision)

## üìä Workflow Complet

### 1. Pr√©paration des Donn√©es

```bash
# Analyser la distribution des classes dans vos donn√©es
python analyze_classes.py

# Pr√©parer et nettoyer les donn√©es
python prepare_data.py
```

### 2. Entra√Ænement du Mod√®le

```bash
# Lancer l'entra√Ænement
python train_model.py

# Surveiller l'entra√Ænement avec TensorBoard (dans un autre terminal)
tensorboard --logdir=logs
# Puis ouvrir http://localhost:6006
```

L'entra√Ænement :
- Charge les donn√©es depuis `data/prepared/complaints_processed.csv`
- Cr√©e des embeddings Word2Vec pour comprendre le sens des mots
- Entra√Æne un r√©seau de neurones hybride CNN + LSTM
- Sauvegarde automatiquement le meilleur mod√®le
- G√©n√®re les fichiers :
  - `models/complaint_classifier.keras` : Mod√®le principal
  - `models/best_model.keras` : Meilleur mod√®le (validation)
  - `models/w2v.wv` : Embeddings Word2Vec
  - `models/class_mapping.json` : Mapping des cat√©gories

### 3. Pr√©diction

```bash
# Pr√©dire la cat√©gorie d'une plainte
python predict.py "I have an issue with my credit card payment"

# Exemples
python predict.py "My mortgage application was rejected without explanation"
python predict.py "I received unauthorized charges on my debit card"
python predict.py "The debt collector keeps calling me at work"
```

Output exemple :
```
üìä Analyse de la plainte:
Texte: "I have an issue with my credit card payment"

üìÅ Cat√©gorie d√©tect√©e: Credit card or prepaid card
üí™ Confiance: 87.3%

üìà Top 5 cat√©gories probables:
  ‚Ä¢ Credit card or prepaid card: 87.3%
  ‚Ä¢ Credit card: 8.1%
  ‚Ä¢ Debt collection: 2.5%
  ‚Ä¢ Bank account or service: 1.2%
  ‚Ä¢ Consumer Loan: 0.9%
```

## üìÅ Structure du Projet

```
support-classification/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # Donn√©es brutes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ complaints.csv           # Dataset original (300k+ plaintes)
‚îÇ   ‚îî‚îÄ‚îÄ prepared/                    # Donn√©es pr√©trait√©es
‚îÇ       ‚îú‚îÄ‚îÄ complaints_processed.csv # Donn√©es nettoy√©es
‚îÇ       ‚îî‚îÄ‚îÄ analyse_result.json      # Statistiques des classes
‚îÇ
‚îú‚îÄ‚îÄ models/                          # Mod√®les sauvegard√©s
‚îÇ   ‚îú‚îÄ‚îÄ complaint_classifier.keras   # Mod√®le principal
‚îÇ   ‚îú‚îÄ‚îÄ best_model.keras            # Meilleur mod√®le (validation)
‚îÇ   ‚îú‚îÄ‚îÄ w2v.wv                      # Embeddings Word2Vec
‚îÇ   ‚îî‚îÄ‚îÄ class_mapping.json          # Mapping des cat√©gories
‚îÇ
‚îú‚îÄ‚îÄ logs/                           # Logs TensorBoard
‚îÇ
‚îú‚îÄ‚îÄ venv/                           # Environnement virtuel Python (non versionn√©)
‚îÇ
‚îú‚îÄ‚îÄ prepare_data.py                 # Pr√©paration et nettoyage des donn√©es
‚îú‚îÄ‚îÄ analyze_classes.py              # Analyse de la distribution des classes
‚îú‚îÄ‚îÄ train_model.py                  # Entra√Ænement du mod√®le
‚îú‚îÄ‚îÄ predict.py                      # Pr√©dictions sur nouveaux textes
‚îú‚îÄ‚îÄ confusion_matrix.py             # G√©n√©ration de la matrice de confusion
‚îÇ
‚îú‚îÄ‚îÄ .env                            # Variables d'environnement
‚îú‚îÄ‚îÄ requirements.txt                # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                       # Documentation (ce fichier)
```

## üèóÔ∏è Architecture du Mod√®le

Le syst√®me utilise une architecture de deep learning sophistiqu√©e :

1. **Word2Vec (100 dimensions)** : Comprend le sens s√©mantique des mots
2. **Conv1D (2 couches)** : D√©tecte les patterns locaux dans le texte
3. **MaxPooling** : R√©duit la dimensionnalit√© et garde les features importantes
4. **LSTM (2 couches, 256+128 unit√©s)** : Comprend le contexte et les s√©quences
5. **Dropout (0.5)** : Pr√©vient le surapprentissage
6. **Dense (128 unit√©s)** : Couche de d√©cision
7. **Sortie (21 classes)** : Classification finale avec softmax

**Caract√©ristiques :**
- ~650k param√®tres entra√Ænables
- Support GPU (CUDA) pour entra√Ænement rapide
- Early stopping pour √©viter le surapprentissage
- Sauvegarde automatique du meilleur mod√®le

## üìà Performances

### M√©triques typiques
- **Accuracy** : 40-60% sur 21 classes (avec 10k exemples)
- **Accuracy** : 70-85% sur 21 classes (avec 50k+ exemples)
- **Temps d'entra√Ænement** :
  - CPU : 30-60 minutes (50k exemples)
  - GPU : 5-10 minutes (50k exemples)

### Optimisation des performances
1. **Plus de donn√©es** : Utiliser `NB_COMMENT=50000` ou plus
2. **S√©quences plus longues** : `MAX_LENGTH=256` pour plus de contexte
3. **Plus d'√©poques** : Modifier `epochs=20` dans train_model.py
4. **Ajuster l'architecture** : Ajouter des couches ou augmenter les unit√©s

## üîß R√©solution de Probl√®mes

### Erreur de m√©moire (Killed)
**Sympt√¥me** : Le script s'arr√™te avec "Killed" pendant la vectorisation

**Solutions** :
1. R√©duire `NB_COMMENT` dans `.env` (ex: 10000)
2. R√©duire `MAX_LENGTH` dans `.env` (ex: 64)
3. Utiliser `dtype=float32` (d√©j√† configur√©)
4. Fermer d'autres applications
5. Augmenter le swap Linux si n√©cessaire

### Faible pr√©cision
**Solutions** :
1. Augmenter `NB_COMMENT` pour plus de donn√©es
2. Augmenter `MAX_LENGTH` pour plus de contexte
3. Entra√Æner plus longtemps (augmenter epochs)
4. V√©rifier le d√©s√©quilibre des classes avec `analyze_classes.py`

### GPU non d√©tect√©
**Solutions** :
1. Installer CUDA et cuDNN compatibles
2. Installer tensorflow-gpu : `pip install tensorflow-gpu`
3. V√©rifier avec : `python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"`

## üöÄ Utilisation Avanc√©e

### Entra√Ænement avec param√®tres personnalis√©s

Modifier directement dans `.env` ou cr√©er plusieurs fichiers de config :

```bash
# Cr√©er une config de production
cp .env .env.production
# √âditer .env.production avec des valeurs plus √©lev√©es

# Utiliser la config de production
cp .env.production .env
python train_model.py
```

### API REST (exemple)

```python
# api.py (exemple simple avec Flask)
from flask import Flask, request, jsonify
import predict

app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict_category():
    text = request.json['text']
    category, confidence, _ = predict.predict_complaint(text)
    return jsonify({
        'category': category,
        'confidence': confidence
    })

if __name__ == '__main__':
    app.run(port=5000)
```


## üìä Monitoring et M√©triques

### TensorBoard

Pendant l'entra√Ænement, surveillez :
- **Loss** : Doit diminuer progressivement
- **Accuracy** : Doit augmenter progressivement
- **Val_loss vs Train_loss** : Si l'√©cart augmente = surapprentissage

```bash
tensorboard --logdir=logs --port=6006
```

### M√©triques personnalis√©es

Le mod√®le g√©n√®re automatiquement :
- Matrice de confusion (apr√®s entra√Ænement)
- Pr√©cision par classe
- F1-score pond√©r√©
- Rapport de classification d√©taill√©

## üìä Matrice de Confusion

### Qu'est-ce qu'une matrice de confusion ?

Une **matrice de confusion** est un outil essentiel pour √©valuer les performances d'un mod√®le de classification. Elle pr√©sente sous forme de tableau le nombre de pr√©dictions correctes et incorrectes pour chaque cat√©gorie.

### G√©n√©ration de la matrice

```bash
# G√©n√©rer la matrice avec toutes les donn√©es de test
python confusion_matrix.py

# Ou limiter le nombre d'√©chantillons pour des tests rapides
python confusion_matrix.py --samples 5000
```

### Visualisations g√©n√©r√©es

Le script `confusion_matrix.py` g√©n√®re plusieurs analyses :

1. **Matrice de confusion standard** : Affiche le nombre absolu de pr√©dictions pour chaque combinaison classe r√©elle/classe pr√©dite
2. **Matrice de confusion normalis√©e** : Affiche les pourcentages pour mieux comprendre les taux d'erreur
3. **M√©triques de performance** :
   - Accuracy globale du mod√®le
   - Pr√©cision, rappel et F1-score par cat√©gorie
   - Top 5 des meilleures et pires classes
4. **Analyse des confusions** : Identifie les erreurs de classification les plus fr√©quentes

### Interpr√©tation des r√©sultats

- **Diagonale principale** : Pr√©dictions correctes (plus les valeurs sont √©lev√©es, mieux c'est)
- **Hors diagonale** : Erreurs de classification (indiquent quelles cat√©gories sont confondues)
- **Classes probl√©matiques** : Les cat√©gories avec beaucoup de confusions sugg√®rent des similarit√©s dans le langage utilis√©

### Exemple de r√©sultats typiques

Avec 10k √©chantillons d'entra√Ænement :
- **Accuracy globale** : 25-40% sur 21 classes
- **Meilleures classes** : "Credit reporting" (50%+ F1-score)
- **Confusions fr√©quentes** : Les produits de cr√©dit similaires (cartes, pr√™ts) sont souvent confondus

### Fichiers g√©n√©r√©s

Les r√©sultats sont sauvegard√©s dans le dossier `models/` :
- `confusion_matrix_[timestamp].png` : Matrice visuelle avec nombres absolus
- `confusion_matrix_normalized_[timestamp].png` : Matrice en pourcentages
- `classification_report_[timestamp].json` : M√©triques d√©taill√©es en JSON

## üìö Objectifs P√©dagogiques

Ce projet √©ducatif permet d'apprendre :

1. **Deep Learning** : Comprendre l'architecture CNN + LSTM
2. **NLP (Natural Language Processing)** : Traitement du langage naturel avec Word2Vec
3. **Classification Multi-classes** : G√©rer 21 cat√©gories diff√©rentes
4. **Pr√©paration des Donn√©es** : Nettoyage et preprocessing de textes
5. **Gestion du D√©s√©quilibre** : Traiter des classes d√©s√©quilibr√©es
6. **Optimisation M√©moire** : G√©rer des datasets volumineux efficacement
7. **MLOps Basique** : Configuration, monitoring avec TensorBoard, versioning des mod√®les

### Exercices Sugg√©r√©s

Pour approfondir votre apprentissage :

1. **Exp√©rimentez avec les hyperparam√®tres** dans `.env`
2. **Analysez l'impact** du nombre d'exemples d'entra√Ænement sur la pr√©cision
3. **Comparez les performances** avec diff√©rentes valeurs de MAX_LENGTH
4. **Visualisez les m√©triques** dans TensorBoard pendant l'entra√Ænement
5. **Testez le mod√®le** avec vos propres exemples de plaintes
6. **√âtudiez la matrice de confusion** pour comprendre les erreurs du mod√®le

## ‚ö†Ô∏è Notes Importantes

1. **Dataset** : Le syst√®me est entra√Æn√© sur des donn√©es publiques de plaintes financi√®res (CFPB)
2. **Langue** : Actuellement optimis√© pour l'anglais uniquement
3. **RGPD** : Assurez-vous de respecter les r√©glementations sur les donn√©es personnelles
4. **Biais** : Le mod√®le peut refl√©ter les biais pr√©sents dans les donn√©es d'entra√Ænement

## üìù Licence

MIT License - Voir fichier LICENSE pour plus de d√©tails

## üìß Support

Pour toute question ou probl√®me :
- Ouvrir une issue sur GitHub
- Email : [votre-email]
- Documentation : [lien-vers-docs]

---

**Derni√®re mise √† jour** : Novembre 2024
**Version** : 1.0.0
**Type** : Projet √âducatif üìö
**Niveau** : Interm√©diaire/Avanc√©