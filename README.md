# Classification de Plaintes Service Client - Projet Ã‰ducatif

SystÃ¨me de classification automatique des plaintes clients utilisant le Deep Learning (CNN + LSTM) et Word2Vec. Ce projet Ã©ducatif dÃ©montre comment utiliser l'apprentissage profond pour catÃ©goriser automatiquement des textes dans 21 catÃ©gories de produits financiers diffÃ©rents.

## ğŸ“‹ Description

Ce projet utilise l'intelligence artificielle pour classifier automatiquement les plaintes des clients dans diffÃ©rentes catÃ©gories de produits financiers (cartes de crÃ©dit, prÃªts immobiliers, comptes bancaires, etc.). Le systÃ¨me analyse le texte des plaintes en anglais et prÃ©dit la catÃ©gorie appropriÃ©e avec un niveau de confiance, permettant ainsi un traitement plus rapide et efficace des demandes clients.

### PrÃ©requis de Connaissances

Ce projet est idÃ©al pour les Ã©tudiants et dÃ©veloppeurs ayant :
- Des bases en **Python** (numpy, pandas)
- Une comprÃ©hension basique du **Machine Learning**
- Un intÃ©rÃªt pour le **Deep Learning** et le **NLP**
- Envie d'apprendre les **rÃ©seaux de neurones** (CNN, LSTM)

## ğŸ¯ CatÃ©gories SupportÃ©es

Le systÃ¨me peut classifier les plaintes dans 21 catÃ©gories de produits financiers, incluant :
- Credit reporting and repair services
- Debt collection
- Mortgage
- Credit cards
- Checking/savings accounts
- Student loans
- Vehicle loans
- Payday loans
- Money transfers
- Et plus encore...

## ğŸš€ Installation Rapide

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Au moins 8 GB de RAM pour l'entraÃ®nement complet (4 GB pour le mode rÃ©duit)
- GPU NVIDIA avec CUDA (optionnel, mais recommandÃ©)

### Installation

1. **Cloner le projet**
```bash
git clone <url-du-projet>
cd support-classification
```

2. **CrÃ©er et activer l'environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Sur Linux/Mac
# ou
venv\Scripts\activate  # Sur Windows
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **TÃ©lÃ©charger le modÃ¨le de langue anglaise pour Spacy**
```bash
python -m spacy download en_core_web_sm
```

5. **CrÃ©er les dossiers nÃ©cessaires**
```bash
mkdir -p data/raw data/prepared models logs
```

## âš™ï¸ Configuration

Le fichier `.env` contient tous les paramÃ¨tres configurables :

```env
# Chemin vers le fichier de donnÃ©es
INPUT_FILE=data/raw/complaints.csv

# ParamÃ¨tres d'entraÃ®nement
NB_COMMENT=10000        # Nombre d'exemples Ã  utiliser (10k pour test, 50k+ pour production)
W2V_SIZE=100           # Dimension des vecteurs Word2Vec
W2V_MIN_COUNT=3        # FrÃ©quence minimale des mots
MAX_LENGTH=64          # Longueur maximale des textes (64 pour Ã©conomiser la RAM, 256 pour meilleure prÃ©cision)

# Nom du modÃ¨le
OUTPUT_FILE=complaint_classifier
```

**Conseils de configuration :**
- **DÃ©veloppement/Test** : `NB_COMMENT=10000`, `MAX_LENGTH=64` (utilise ~2GB RAM)
- **Production** : `NB_COMMENT=50000`, `MAX_LENGTH=256` (utilise ~8GB RAM, meilleure prÃ©cision)

## ğŸ“Š Workflow Complet

### 1. PrÃ©paration des DonnÃ©es

```bash
# Analyser la distribution des classes dans vos donnÃ©es
python analyze_classes.py

# PrÃ©parer et nettoyer les donnÃ©es
python prepare_data.py
```

### 2. EntraÃ®nement du ModÃ¨le

```bash
# Lancer l'entraÃ®nement
python train_model.py

# Surveiller l'entraÃ®nement avec TensorBoard (dans un autre terminal)
tensorboard --logdir=logs
# Puis ouvrir http://localhost:6006
```

L'entraÃ®nement :
- Charge les donnÃ©es depuis `data/prepared/complaints_processed.csv`
- CrÃ©e des embeddings Word2Vec pour comprendre le sens des mots
- EntraÃ®ne un rÃ©seau de neurones hybride CNN + LSTM
- Sauvegarde automatiquement le meilleur modÃ¨le
- GÃ©nÃ¨re les fichiers :
  - `models/complaint_classifier.keras` : ModÃ¨le principal
  - `models/best_model.keras` : Meilleur modÃ¨le (validation)
  - `models/w2v.wv` : Embeddings Word2Vec
  - `models/class_mapping.json` : Mapping des catÃ©gories

### 3. PrÃ©diction

```bash
# PrÃ©dire la catÃ©gorie d'une plainte
python predict.py "I have an issue with my credit card payment"

# Exemples
python predict.py "My mortgage application was rejected without explanation"
python predict.py "I received unauthorized charges on my debit card"
python predict.py "The debt collector keeps calling me at work"
```

Output exemple :
```
ğŸ“Š Analyse de la plainte:
Texte: "I have an issue with my credit card payment"

ğŸ“ CatÃ©gorie dÃ©tectÃ©e: Credit card or prepaid card
ğŸ’ª Confiance: 87.3%

ğŸ“ˆ Top 5 catÃ©gories probables:
  â€¢ Credit card or prepaid card: 87.3%
  â€¢ Credit card: 8.1%
  â€¢ Debt collection: 2.5%
  â€¢ Bank account or service: 1.2%
  â€¢ Consumer Loan: 0.9%
```

## ğŸ“ Structure du Projet

```
support-classification/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # DonnÃ©es brutes
â”‚   â”‚   â””â”€â”€ complaints.csv           # Dataset original (300k+ plaintes)
â”‚   â””â”€â”€ prepared/                    # DonnÃ©es prÃ©traitÃ©es
â”‚       â”œâ”€â”€ complaints_processed.csv # DonnÃ©es nettoyÃ©es
â”‚       â””â”€â”€ analyse_result.json      # Statistiques des classes
â”‚
â”œâ”€â”€ models/                          # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ complaint_classifier.keras   # ModÃ¨le principal
â”‚   â”œâ”€â”€ best_model.keras            # Meilleur modÃ¨le (validation)
â”‚   â”œâ”€â”€ w2v.wv                      # Embeddings Word2Vec
â”‚   â””â”€â”€ class_mapping.json          # Mapping des catÃ©gories
â”‚
â”œâ”€â”€ logs/                           # Logs TensorBoard
â”‚
â”œâ”€â”€ venv/                           # Environnement virtuel Python (non versionnÃ©)
â”‚
â”œâ”€â”€ prepare_data.py                 # PrÃ©paration et nettoyage des donnÃ©es
â”œâ”€â”€ analyze_classes.py              # Analyse de la distribution des classes
â”œâ”€â”€ train_model.py                  # EntraÃ®nement du modÃ¨le
â”œâ”€â”€ predict.py                      # PrÃ©dictions sur nouveaux textes
â”‚
â”œâ”€â”€ .env                            # Variables d'environnement
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â””â”€â”€ README.md                       # Documentation (ce fichier)
```

## ğŸ—ï¸ Architecture du ModÃ¨le

Le systÃ¨me utilise une architecture de deep learning sophistiquÃ©e :

1. **Word2Vec (100 dimensions)** : Comprend le sens sÃ©mantique des mots
2. **Conv1D (2 couches)** : DÃ©tecte les patterns locaux dans le texte
3. **MaxPooling** : RÃ©duit la dimensionnalitÃ© et garde les features importantes
4. **LSTM (2 couches, 256+128 unitÃ©s)** : Comprend le contexte et les sÃ©quences
5. **Dropout (0.5)** : PrÃ©vient le surapprentissage
6. **Dense (128 unitÃ©s)** : Couche de dÃ©cision
7. **Sortie (21 classes)** : Classification finale avec softmax

**CaractÃ©ristiques :**
- ~650k paramÃ¨tres entraÃ®nables
- Support GPU (CUDA) pour entraÃ®nement rapide
- Early stopping pour Ã©viter le surapprentissage
- Sauvegarde automatique du meilleur modÃ¨le

## ğŸ“ˆ Performances

### MÃ©triques typiques
- **Accuracy** : 40-60% sur 21 classes (avec 10k exemples)
- **Accuracy** : 70-85% sur 21 classes (avec 50k+ exemples)
- **Temps d'entraÃ®nement** :
  - CPU : 30-60 minutes (50k exemples)
  - GPU : 5-10 minutes (50k exemples)

### Optimisation des performances
1. **Plus de donnÃ©es** : Utiliser `NB_COMMENT=50000` ou plus
2. **SÃ©quences plus longues** : `MAX_LENGTH=256` pour plus de contexte
3. **Plus d'Ã©poques** : Modifier `epochs=20` dans train_model.py
4. **Ajuster l'architecture** : Ajouter des couches ou augmenter les unitÃ©s

## ğŸ”§ RÃ©solution de ProblÃ¨mes

### Erreur de mÃ©moire (Killed)
**SymptÃ´me** : Le script s'arrÃªte avec "Killed" pendant la vectorisation

**Solutions** :
1. RÃ©duire `NB_COMMENT` dans `.env` (ex: 10000)
2. RÃ©duire `MAX_LENGTH` dans `.env` (ex: 64)
3. Utiliser `dtype=float32` (dÃ©jÃ  configurÃ©)
4. Fermer d'autres applications
5. Augmenter le swap Linux si nÃ©cessaire

### Faible prÃ©cision
**Solutions** :
1. Augmenter `NB_COMMENT` pour plus de donnÃ©es
2. Augmenter `MAX_LENGTH` pour plus de contexte
3. EntraÃ®ner plus longtemps (augmenter epochs)
4. VÃ©rifier le dÃ©sÃ©quilibre des classes avec `analyze_classes.py`

### GPU non dÃ©tectÃ©
**Solutions** :
1. Installer CUDA et cuDNN compatibles
2. Installer tensorflow-gpu : `pip install tensorflow-gpu`
3. VÃ©rifier avec : `python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"`

## ğŸš€ Utilisation AvancÃ©e

### EntraÃ®nement avec paramÃ¨tres personnalisÃ©s

Modifier directement dans `.env` ou crÃ©er plusieurs fichiers de config :

```bash
# CrÃ©er une config de production
cp .env .env.production
# Ã‰diter .env.production avec des valeurs plus Ã©levÃ©es

# Utiliser la config de production
cp .env.production .env
python train_model.py
```

### API REST (exemple)

```python
# api.py (exemple simple avec Flask)
from flask import Flask, request, jsonify
import predict

app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict_category():
    text = request.json['text']
    category, confidence, _ = predict.predict_complaint(text)
    return jsonify({
        'category': category,
        'confidence': confidence
    })

if __name__ == '__main__':
    app.run(port=5000)
```


## ğŸ“Š Monitoring et MÃ©triques

### TensorBoard

Pendant l'entraÃ®nement, surveillez :
- **Loss** : Doit diminuer progressivement
- **Accuracy** : Doit augmenter progressivement
- **Val_loss vs Train_loss** : Si l'Ã©cart augmente = surapprentissage

```bash
tensorboard --logdir=logs --port=6006
```

### MÃ©triques personnalisÃ©es

Le modÃ¨le gÃ©nÃ¨re automatiquement :
- Matrice de confusion (aprÃ¨s entraÃ®nement)
- PrÃ©cision par classe
- F1-score pondÃ©rÃ©
- Rapport de classification dÃ©taillÃ©

## ğŸ“š Objectifs PÃ©dagogiques

Ce projet Ã©ducatif permet d'apprendre :

1. **Deep Learning** : Comprendre l'architecture CNN + LSTM
2. **NLP (Natural Language Processing)** : Traitement du langage naturel avec Word2Vec
3. **Classification Multi-classes** : GÃ©rer 21 catÃ©gories diffÃ©rentes
4. **PrÃ©paration des DonnÃ©es** : Nettoyage et preprocessing de textes
5. **Gestion du DÃ©sÃ©quilibre** : Traiter des classes dÃ©sÃ©quilibrÃ©es
6. **Optimisation MÃ©moire** : GÃ©rer des datasets volumineux efficacement
7. **MLOps Basique** : Configuration, monitoring avec TensorBoard, versioning des modÃ¨les

### Exercices SuggÃ©rÃ©s

Pour approfondir votre apprentissage :

1. **ExpÃ©rimentez avec les hyperparamÃ¨tres** dans `.env`
2. **Analysez l'impact** du nombre d'exemples d'entraÃ®nement sur la prÃ©cision
3. **Comparez les performances** avec diffÃ©rentes valeurs de MAX_LENGTH
4. **Visualisez les mÃ©triques** dans TensorBoard pendant l'entraÃ®nement
5. **Testez le modÃ¨le** avec vos propres exemples de plaintes
6. **Ã‰tudiez la matrice de confusion** pour comprendre les erreurs du modÃ¨le

## âš ï¸ Notes Importantes

1. **Dataset** : Le systÃ¨me est entraÃ®nÃ© sur des donnÃ©es publiques de plaintes financiÃ¨res (CFPB)
2. **Langue** : Actuellement optimisÃ© pour l'anglais uniquement
3. **RGPD** : Assurez-vous de respecter les rÃ©glementations sur les donnÃ©es personnelles
4. **Biais** : Le modÃ¨le peut reflÃ©ter les biais prÃ©sents dans les donnÃ©es d'entraÃ®nement

## ğŸ“ Licence

MIT License - Voir fichier LICENSE pour plus de dÃ©tails

## ğŸ“§ Support

Pour toute question ou problÃ¨me :
- Ouvrir une issue sur GitHub
- Email : [votre-email]
- Documentation : [lien-vers-docs]

---

**DerniÃ¨re mise Ã  jour** : Novembre 2024
**Version** : 1.0.0
**Type** : Projet Ã‰ducatif ğŸ“š
**Niveau** : IntermÃ©diaire/AvancÃ©