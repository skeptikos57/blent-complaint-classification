"""Script pour g√©n√©rer et visualiser la matrice de confusion du mod√®le.

Ce script :
1. Charge le mod√®le entra√Æn√© et les donn√©es de test
2. Fait des pr√©dictions sur l'ensemble de test
3. G√©n√®re une matrice de confusion
4. Cr√©e des visualisations et calcule les m√©triques de performance
5. Sauvegarde les r√©sultats dans un fichier

Usage:
    python confusion_matrix.py
    python confusion_matrix.py --samples 5000  # Limiter le nombre d'√©chantillons
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from dotenv import load_dotenv
import json
from datetime import datetime

# Configuration pour r√©duire les messages de TensorFlow
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

import tensorflow as tf
from gensim.models import KeyedVectors
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# Charger les variables d'environnement
load_dotenv(override=True)

# Configuration des param√®tres
W2V_SIZE = int(os.getenv("W2V_SIZE", 100))
MAX_LENGTH = int(os.getenv("MAX_LENGTH", 64))
OUTPUT_FILE = os.getenv("OUTPUT_FILE", "complaint_classifier")


def load_models_and_data():
    """Charge les mod√®les et le mapping des classes."""
    print("\nüìÇ Chargement des mod√®les...")
    
    # Charger le mod√®le de classification
    model_path = f"models/{OUTPUT_FILE}.keras"
    if not os.path.exists(model_path):
        print(f"‚ùå Erreur: Le mod√®le {model_path} n'existe pas.")
        print("Veuillez d'abord entra√Æner le mod√®le avec train_model.py")
        sys.exit(1)
    
    model = tf.keras.models.load_model(model_path)
    print(f"‚úÖ Mod√®le charg√© depuis {model_path}")
    
    # Charger Word2Vec
    w2v = KeyedVectors.load("models/w2v.wv")
    print("‚úÖ Word2Vec charg√©")
    
    # Charger le mapping des classes
    with open('models/class_mapping.json', 'r', encoding='utf-8') as f:
        class_data = json.load(f)
    print("‚úÖ Mapping des classes charg√©")
    
    return model, w2v, class_data


def load_and_prepare_data(max_samples=None):
    """Charge et pr√©pare les donn√©es de test."""
    print("\nüìä Chargement des donn√©es...")
    
    # Charger les donn√©es
    data_path = 'data/prepared/complaints_processed.csv'
    if not os.path.exists(data_path):
        print(f"‚ùå Erreur: Le fichier {data_path} n'existe pas.")
        print("Veuillez d'abord pr√©parer les donn√©es avec prepare_data.py")
        sys.exit(1)
    
    data = pd.read_csv(data_path)
    
    # Limiter le nombre d'√©chantillons si demand√©
    if max_samples and len(data) > max_samples:
        data = data.sample(n=max_samples, random_state=42)
        print(f"üìâ Donn√©es limit√©es √† {max_samples} √©chantillons")
    
    print(f"‚úÖ {len(data)} √©chantillons charg√©s")
    
    return data


def tokenize_text(text):
    """Tokenise un texte en mots."""
    import re
    # Simple tokenization
    text = text.lower()
    # Garder seulement lettres et espaces
    text = re.sub(r'[^a-z\s]', '', text)
    # Diviser en mots
    words = text.split()
    return words


def text_to_vector(text, w2v):
    """Convertit un texte en matrice de vecteurs Word2Vec."""
    # Tokeniser le texte
    tokens = tokenize_text(text)
    
    # Cr√©er la matrice de vecteurs
    matrix = np.zeros((W2V_SIZE, MAX_LENGTH), dtype=np.float32)
    
    # Remplir avec les vecteurs des mots
    for j, word in enumerate(tokens[:MAX_LENGTH]):
        if word in w2v:  # KeyedVectors n'a pas d'attribut wv
            matrix[:, j] = w2v[word]
    
    return matrix


def predict_batch(model, texts, w2v, batch_size=32):
    """Fait des pr√©dictions par batch pour √©conomiser la m√©moire."""
    predictions = []
    n_batches = (len(texts) + batch_size - 1) // batch_size
    
    print(f"\nüîÆ G√©n√©ration des pr√©dictions ({n_batches} batches)...")
    
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        batch_vectors = []
        
        for text in batch_texts:
            vector = text_to_vector(text, w2v)
            batch_vectors.append(vector)
        
        batch_array = np.array(batch_vectors)
        batch_preds = model.predict(batch_array, verbose=0)
        predictions.extend(batch_preds)
        
        # Afficher la progression
        progress = min(i + batch_size, len(texts))
        print(f"  {progress}/{len(texts)} √©chantillons trait√©s ({progress*100/len(texts):.1f}%)", end='\r')
    
    print(f"\n‚úÖ Pr√©dictions termin√©es pour {len(texts)} √©chantillons")
    return np.array(predictions)


def generate_confusion_matrix(y_true, y_pred, class_names):
    """G√©n√®re et affiche la matrice de confusion."""
    
    # Calculer la matrice de confusion
    cm = confusion_matrix(y_true, y_pred)
    
    # Cr√©er la figure
    plt.figure(figsize=(20, 16))
    
    # Utiliser une palette de couleurs adapt√©e
    # Pour une meilleure lisibilit√© avec beaucoup de classes
    sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd', 
                xticklabels=class_names, 
                yticklabels=class_names,
                cbar_kws={'label': 'Nombre de pr√©dictions'})
    
    plt.title('Matrice de Confusion - Classification des Plaintes\n', fontsize=16, fontweight='bold')
    plt.xlabel('Classe Pr√©dite', fontsize=12)
    plt.ylabel('Classe R√©elle', fontsize=12)
    
    # Rotation des labels pour meilleure lisibilit√©
    plt.xticks(rotation=45, ha='right', fontsize=8)
    plt.yticks(rotation=0, fontsize=8)
    
    plt.tight_layout()
    
    # Sauvegarder la figure
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"models/confusion_matrix_{timestamp}.png"
    plt.savefig(filename, dpi=150, bbox_inches='tight')
    print(f"\nüíæ Matrice de confusion sauvegard√©e dans {filename}")
    
    return cm


def generate_normalized_matrix(y_true, y_pred, class_names):
    """G√©n√®re une matrice de confusion normalis√©e (en pourcentages)."""
    
    # Calculer la matrice de confusion normalis√©e
    cm = confusion_matrix(y_true, y_pred)
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100
    
    # Cr√©er la figure
    plt.figure(figsize=(20, 16))
    
    # Afficher avec des pourcentages
    sns.heatmap(cm_normalized, annot=True, fmt='.1f', cmap='Blues',
                xticklabels=class_names,
                yticklabels=class_names,
                cbar_kws={'label': 'Pourcentage (%)'})
    
    plt.title('Matrice de Confusion Normalis√©e - Classification des Plaintes\n', fontsize=16, fontweight='bold')
    plt.xlabel('Classe Pr√©dite', fontsize=12)
    plt.ylabel('Classe R√©elle', fontsize=12)
    
    # Rotation des labels
    plt.xticks(rotation=45, ha='right', fontsize=8)
    plt.yticks(rotation=0, fontsize=8)
    
    plt.tight_layout()
    
    # Sauvegarder
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"models/confusion_matrix_normalized_{timestamp}.png"
    plt.savefig(filename, dpi=150, bbox_inches='tight')
    print(f"üíæ Matrice normalis√©e sauvegard√©e dans {filename}")
    
    return cm_normalized


def calculate_metrics(y_true, y_pred, class_names):
    """Calcule et affiche les m√©triques de performance."""
    
    print("\nüìà M√©triques de Performance")
    print("=" * 60)
    
    # Accuracy globale
    accuracy = accuracy_score(y_true, y_pred)
    print(f"\nüéØ Accuracy globale: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # Rapport de classification d√©taill√©
    # Obtenir les labels uniques pr√©sents dans les donn√©es
    unique_labels = sorted(set(y_true) | set(y_pred))
    target_names_filtered = [class_names[i] for i in unique_labels]
    
    report = classification_report(y_true, y_pred, 
                                  labels=unique_labels,
                                  target_names=target_names_filtered,
                                  output_dict=True,
                                  zero_division=0)
    
    # Sauvegarder le rapport dans un fichier
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"models/classification_report_{timestamp}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ Rapport d√©taill√© sauvegard√© dans {report_file}")
    
    # Afficher les m√©triques par classe (top 5 meilleures et pires)
    class_metrics = []
    for class_name in class_names:
        if class_name in report:
            metrics = report[class_name]
            class_metrics.append({
                'Classe': class_name[:40],  # Tronquer les noms longs
                'Pr√©cision': metrics['precision'],
                'Rappel': metrics['recall'],
                'F1-Score': metrics['f1-score'],
                'Support': int(metrics['support'])
            })
    
    # Convertir en DataFrame pour un affichage plus joli
    df_metrics = pd.DataFrame(class_metrics)
    df_metrics = df_metrics.sort_values('F1-Score', ascending=False)
    
    print("\nüèÜ Top 5 classes (meilleur F1-Score):")
    print(df_metrics.head(5).to_string(index=False))
    
    print("\n‚ö†Ô∏è Bottom 5 classes (plus faible F1-Score):")
    print(df_metrics.tail(5).to_string(index=False))
    
    # M√©triques moyennes pond√©r√©es
    print("\nüìä M√©triques moyennes pond√©r√©es:")
    print(f"  ‚Ä¢ Pr√©cision: {report['weighted avg']['precision']:.4f}")
    print(f"  ‚Ä¢ Rappel: {report['weighted avg']['recall']:.4f}")
    print(f"  ‚Ä¢ F1-Score: {report['weighted avg']['f1-score']:.4f}")
    
    return report


def analyze_confusion_patterns(cm, class_names):
    """Analyse les principales confusions dans la matrice."""
    
    print("\nüîç Analyse des Confusions Principales")
    print("=" * 60)
    
    # Pour chaque classe, trouver avec quoi elle est le plus confondue
    confusions = []
    
    # La matrice peut √™tre plus petite que le nombre total de classes
    # si certaines classes ne sont pas pr√©sentes dans l'√©chantillon
    matrix_size = cm.shape[0]
    
    for i in range(matrix_size):
        for j in range(matrix_size):
            if i != j and i < len(class_names) and j < len(class_names) and cm[i, j] > 0:  # Ignorer la diagonale et les z√©ros
                confusions.append({
                    'Vraie classe': class_names[i][:30],
                    'Pr√©dite comme': class_names[j][:30],
                    'Nombre': cm[i, j],
                    'Pourcentage': (cm[i, j] / cm[i].sum() * 100) if cm[i].sum() > 0 else 0
                })
    
    # Trier par nombre de confusions
    confusions = sorted(confusions, key=lambda x: x['Nombre'], reverse=True)
    
    # Afficher les 10 principales confusions
    print("\nTop 10 des confusions les plus fr√©quentes:")
    for i, conf in enumerate(confusions[:10], 1):
        print(f"{i:2d}. {conf['Vraie classe']} ‚Üí {conf['Pr√©dite comme']}")
        print(f"    {conf['Nombre']} fois ({conf['Pourcentage']:.1f}% des cas)")
    
    # Identifier les classes probl√©matiques
    print("\n‚ö†Ô∏è Classes les plus difficiles √† pr√©dire:")
    diagonal = np.diag(cm)
    row_sums = cm.sum(axis=1)
    accuracies = diagonal / (row_sums + 1e-10)  # √âviter division par z√©ro
    
    # Limiter aux classes pr√©sentes dans la matrice
    difficult_classes = [(class_names[i], acc) for i, acc in enumerate(accuracies) if i < len(class_names)]
    difficult_classes.sort(key=lambda x: x[1])
    
    # Afficher jusqu'√† 5 classes difficiles
    for class_name, acc in difficult_classes[:min(5, len(difficult_classes))]:
        print(f"  ‚Ä¢ {class_name[:40]}: {acc*100:.1f}% de pr√©cision")


def main():
    """Fonction principale."""
    
    print("=" * 60)
    print("üéØ G√âN√âRATION DE LA MATRICE DE CONFUSION")
    print("=" * 60)
    
    # Parser les arguments de ligne de commande
    max_samples = None
    if len(sys.argv) > 1:
        if sys.argv[1] == '--samples' and len(sys.argv) > 2:
            max_samples = int(sys.argv[2])
    
    try:
        # Charger les mod√®les et donn√©es
        model, w2v, class_data = load_models_and_data()
        data = load_and_prepare_data(max_samples)
        
        # Pr√©parer les donn√©es
        print("\nüîÑ Pr√©paration des donn√©es...")
        
        # Mapper les cat√©gories aux indices
        class_mapping = class_data['class_mapping']
        data['label'] = data['product'].map(class_mapping)
        
        # Supprimer les lignes avec des labels manquants
        data = data.dropna(subset=['label'])
        data['label'] = data['label'].astype(int)
        
        # Diviser en train/test (on utilise les m√™mes proportions que l'entra√Ænement)
        # V√©rifier si on peut faire une stratification
        min_class_count = data['label'].value_counts().min()
        if min_class_count >= 2:
            _, test_data = train_test_split(data, test_size=0.2, 
                                           random_state=42, 
                                           stratify=data['label'])
        else:
            # Si certaines classes ont trop peu d'exemples, pas de stratification
            print("‚ö†Ô∏è Certaines classes ont trop peu d'exemples, stratification d√©sactiv√©e")
            _, test_data = train_test_split(data, test_size=0.2, 
                                           random_state=42)
        
        print(f"‚úÖ {len(test_data)} √©chantillons de test pr√©par√©s")
        
        # Faire les pr√©dictions
        X_test = test_data['complaint_text'].values
        y_true = test_data['label'].values
        
        # Pr√©dire par batch
        predictions = predict_batch(model, X_test, w2v)
        y_pred = np.argmax(predictions, axis=1)
        
        # Pr√©parer les noms de classes (tronqu√©s pour l'affichage)
        class_names = [class_data['index_to_class'][str(i)][:30] 
                      for i in range(len(class_data['index_to_class']))]
        
        # G√©n√©rer les matrices de confusion
        print("\nüìä G√©n√©ration des visualisations...")
        cm = generate_confusion_matrix(y_true, y_pred, class_names)
        _ = generate_normalized_matrix(y_true, y_pred, class_names)  # G√©n√®re et sauvegarde la matrice normalis√©e
        
        # Calculer les m√©triques
        _ = calculate_metrics(y_true, y_pred, class_names)  # G√©n√®re et sauvegarde le rapport de classification
        
        # Analyser les patterns de confusion
        analyze_confusion_patterns(cm, class_names)
        
        # Afficher les graphiques
        print("\n‚úÖ Analyse termin√©e!")
        print("üìä Pour voir les graphiques, ouvrez les fichiers PNG dans le dossier models/")
        
        # Optionnel : afficher les graphiques directement
        try:
            plt.show()
        except:
            pass  # Si pas d'environnement graphique
            
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()